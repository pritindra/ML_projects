{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "# import openpyxl\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.127513e+18</td>\n",
       "      <td>RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>hasoc_2020_hi_4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.123822e+18</td>\n",
       "      <td>RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123733e+18</td>\n",
       "      <td>RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.127646e+18</td>\n",
       "      <td>RT @HarishK04131926: @AcharyaPramodk बोलने से ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.127768e+18</td>\n",
       "      <td>RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>hasoc_2020_hi_4304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                                               text task1  \\\n",
       "0  1.127513e+18  RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...   HOF   \n",
       "1  1.123822e+18  RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...   NOT   \n",
       "2  1.123733e+18  RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...   NOT   \n",
       "3  1.127646e+18  RT @HarishK04131926: @AcharyaPramodk बोलने से ...   NOT   \n",
       "4  1.127768e+18  RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...   HOF   \n",
       "\n",
       "  task2                  ID  \n",
       "0  OFFN  hasoc_2020_hi_4007  \n",
       "1  NONE  hasoc_2020_hi_1548  \n",
       "2  NONE   hasoc_2020_hi_612  \n",
       "3  NONE  hasoc_2020_hi_2044  \n",
       "4  HATE  hasoc_2020_hi_4304  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_excel(\"dataset/hindi.xlsx\", engine=\"openpyxl\")\n",
    "wb = load_workbook(\"dataset/hindi.xlsx\")\n",
    "sheet = wb.active\n",
    "col = csv.writer(open(\"tt.csv\", 'w', newline=\"\"))\n",
    "for r in sheet.rows:\n",
    "    col.writerow([cell.value for cell in r])\n",
    "  \n",
    "df = pd.DataFrame(pd.read_csv(\"tt.csv\"))\n",
    "df.to_csv(\"dataset/hindi.csv\", sep=\",\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.127513e+18</td>\n",
       "      <td>RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>hasoc_2020_hi_4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.123822e+18</td>\n",
       "      <td>RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_1548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123733e+18</td>\n",
       "      <td>RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.127646e+18</td>\n",
       "      <td>RT @HarishK04131926: @AcharyaPramodk बोलने से ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>hasoc_2020_hi_2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.127768e+18</td>\n",
       "      <td>RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>hasoc_2020_hi_4304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                                               text task1  \\\n",
       "0  1.127513e+18  RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...   HOF   \n",
       "1  1.123822e+18  RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...   NOT   \n",
       "2  1.123733e+18  RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...   NOT   \n",
       "3  1.127646e+18  RT @HarishK04131926: @AcharyaPramodk बोलने से ...   NOT   \n",
       "4  1.127768e+18  RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...   HOF   \n",
       "\n",
       "  task2                  ID  \n",
       "0  OFFN  hasoc_2020_hi_4007  \n",
       "1  NONE  hasoc_2020_hi_1548  \n",
       "2  NONE   hasoc_2020_hi_612  \n",
       "3  NONE  hasoc_2020_hi_2044  \n",
       "4  HATE  hasoc_2020_hi_4304  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @HarishK04131926: @AcharyaPramodk बोलने से ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  task2\n",
       "0  RT @_SwarajIndia: देश के चुनाव को सुनियोजित तर...    1.0\n",
       "1  RT @YadavsAniruddh: #श्रीनगर में एक #आतंकवादी ...    0.0\n",
       "2  RT @KapilMishra_IND: चाइना ने नेहरू जी की बहुत...    0.0\n",
       "3  RT @HarishK04131926: @AcharyaPramodk बोलने से ...    0.0\n",
       "4  RT @DhirajY09648978: #BJP_भगाओ_देश_बचाओ\\n स्वा...    1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['text', 'task2']\n",
    "df_2 = df[cols]\n",
    "# df_2.replace(to_replace=[\"HATE, OFFN\"], value=\"1\")\n",
    "df_2['task2'] = df_2['task2'].map({'HATE':1,'OFFN':1, 'NONE':0})\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'पहले', 'निहायत', 'सकते', 'मानो', 'कई', 'एस', 'उसने', 'किन्हें', 'जैसा', 'उसी', 'तिस', 'कर', 'द्वारा', 'उसकी', 'अपना', 'अपनी', 'इसमें', 'भि', 'वह', 'इंहों', 'किसे', 'पर', 'क्योंकि', 'तेरा', 'करें', 'हैं', 'हम', 'इसकि', 'तब', 'बिलकुल', 'एसे', 'वरग', 'इन्हीं', 'अंदर', 'उंहों', 'हुअ', 'तू', 'थे', 'उन्होंने', 'होता', 'इसका', 'अनुसार', 'वर्ग', 'जैसे', 'उन्हीं', 'हुई', 'किंहें', 'दिया', 'अभी', 'तरह', 'वह ', 'मेरे', 'यहि', 'वहिं', 'कारण', 'बनि', 'तो', 'तक', 'भीतर', 'तिंहों', 'उनके', 'इसकी', 'करना', 'तुम्हारे', 'रहा', 'रखें', 'देकर', 'कह', 'कोई', 'कुल', 'जब', 'की', 'किया', 'बाला', 'होते', 'इसी', 'दवारा', 'कितना', 'करते', 'अदि', 'गया', 'तिन्हें', 'सभी', 'उस', 'लिये', 'होति', 'जीधर', 'हें', 'हो', 'जेसा', 'करता', 'इसे', 'दूसरे', 'रह', 'वुह ', 'साथ', 'इन', 'तेरे', 'इन ', 'कि', 'कौन', 'पर  ', 'वगेरह', 'दुसरा', 'कहता', 'यही', 'सभि', 'नीचे', 'यिह ', 'होती', 'कोनसा', 'तिंहें', 'उसि', 'सारा', 'आप', 'तुझे', 'व', 'इसलिये', 'वग़ैरह', 'थी', 'कौनसा', 'भी', 'ऱ्वासा', 'सब', 'साम्हने', 'अपने', 'आदि', 'किन्हों', 'भितर', 'किसी', 'एक', 'परन्तु', 'कइ', 'यह', 'जो', 'जिंहें', 'इस', 'बहुत', 'दुसरे', 'इसि', 'दो', 'किसि', 'अत', 'ये', 'मेरी', 'तिन्हों', 'लेकिन', 'किर', 'इत्यादि', 'हुइ', 'बही', 'जहां', 'को', 'तुम', 'हि', 'जिन्हें', 'अर्थात', 'दे', 'जिसे', 'वे', 'किस', 'उन', 'इंहें', 'पुरा', 'किंहों', 'जिन', 'जिंहों', 'मे', 'तिसे', 'उनकी', 'करने', 'और', 'गए', \"इतयादि' ,'यहाँ\", 'उसको', 'पे', 'यहां', 'जहाँ', 'रवासा', 'उनकि', 'उसके', 'ही', 'उन्हों', 'बनी', \"बात' \", 'जिस', 'उनका', 'नहीं', 'घर', 'उसे', 'उसका', 'ले', 'कोन', 'अप', 'जेसे', 'उंहें', 'कुछ', 'या', 'होने', 'मुझ', 'संग', 'अभि', 'ओर', 'क्या', 'पास', 'उन्ह', 'साभ', 'हुए', 'हूं', 'नहिं', 'वहीं', 'उंहिं', 'बाद', 'सो', 'का', 'मैं', 'हे', 'वहां', 'इन्हों', 'इंहिं', 'है', 'तिन', 'हुआ', 'रहे', 'जितना', 'जिन्हों', 'ऐसा', 'निचे', 'सकता', 'सबसे', 'जा', 'इसके', 'ना', 'इनका', 'बहि', 'एवं', 'ऐसे', 'काफि', 'ने', 'तेरी', 'अपनि', 'मगर', 'फिर', 'वहाँ', 'मुझे', 'थि', 'इन्हें', 'वुह', 'वाले', 'कहते', 'दबारा', 'जिधर', 'यदि', 'था', 'उनको', 'कोइ', 'साबुत', 'कहा', 'लिए', 'न', 'उन्हें', 'काफ़ी', 'में', 'के', 'से', 'होना', 'पूरा', 'यिह'}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "with open(\"dataset/Hindi_StopWords.txt\",encoding='utf-8') as f:\n",
    "    stopword= f.read().strip('\\ufeff')\n",
    "stopword = stopword.split(\", \")\n",
    "stopword = [i.strip(\"'\") for i in stopword]\n",
    "\n",
    "stopwords = set(stopword)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "hate_det = df_2[df_2.task2==1]\n",
    "hate_det.reset_index(drop=True, inplace=True)\n",
    "acc_det = df_2[df_2.task2==0]\n",
    "acc_det.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Tokenization\n",
    "hate_news = []\n",
    "for rows in range(0, hate_det.shape[0]):\n",
    "    head_txt = hate_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    hate_news.append(head_txt)\n",
    "    \n",
    "hate_list = list(itertools.chain(*hate_news))\n",
    "# print(hate_list)\n",
    "acc_news = []\n",
    "for rows in range(0, acc_det.shape[0]):\n",
    "    head_txt = acc_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    hate_news.append(head_txt)\n",
    "    \n",
    "acc_list = list(itertools.chain(*acc_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_list_restp = [word for word in hate_list if word.lower() not in stopwords]\n",
    "acc_list_restp = [word for word in acc_list if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common hate words : [('RT', 169), ('', 106), ('मोदी', 49), ('देश', 36), ('नही', 33), ('वोट', 29), ('कांग्रेस', 24), ('जी', 23), ('वो', 21), ('अब', 19)]\n",
      "most common acclaimed words : []\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "hate_count, acc_count = Counter(hate_list_restp), Counter(acc_list_restp)\n",
    "most_hate, most_acc = hate_count.most_common(10), acc_count.most_common(10)\n",
    "print(\"most common hate words : \" + str(most_hate))\n",
    "print(\"most common acclaimed words : \" + str(most_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.text\n",
    "Y = df_2.task2\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "tk.fit_on_texts(X_train)\n",
    "seqs = tk.texts_to_sequences(X_train)\n",
    "max_len = 100\n",
    "seqs_mat = tf.keras.preprocessing.sequence.pad_sequences(seqs,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def():\n",
    "    inputs = tf.keras.layers.Input(name='inputs', shape=[max_len])\n",
    "    layer = tf.keras.layers.Embedding(1000,50,input_length=max_len)(inputs)\n",
    "    layer = tf.keras.layers.LSTM(64)(layer)\n",
    "    layer = tf.keras.layers.Dense(256,name='FC1')(layer)\n",
    "    layer = tf.keras.layers.Activation('relu')(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "    layer = tf.keras.layers.Dense(1,name='out_layer')(layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_def()\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 908 samples, validate on 101 samples\n",
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "908/908 [==============================] - 6s 7ms/sample - loss: -9.7512 - acc: 0.3535 - val_loss: -6.9835 - val_acc: 0.2673\n",
      "Epoch 2/5\n",
      "908/908 [==============================] - 3s 3ms/sample - loss: -15.8061 - acc: 0.2368 - val_loss: -6.9835 - val_acc: 0.2673\n",
      "Epoch 3/5\n",
      "908/908 [==============================] - 3s 3ms/sample - loss: -15.8061 - acc: 0.2368 - val_loss: -6.9835 - val_acc: 0.2673\n",
      "Epoch 4/5\n",
      "908/908 [==============================] - 3s 3ms/sample - loss: -15.8061 - acc: 0.2368 - val_loss: -6.9835 - val_acc: 0.2673\n",
      "Epoch 5/5\n",
      "908/908 [==============================] - 3s 3ms/sample - loss: -15.8061 - acc: 0.2368 - val_loss: -6.9835 - val_acc: 0.2673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92f5eb74a8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    mode='max',\n",
    "    patience=6\n",
    ")\n",
    "# increase epochs and other steps for better training\n",
    "model.fit(seqs_mat,Y_train,batch_size=100,epochs=5,\n",
    "          validation_split=0.1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 0s 2ms/sample - loss: -8.4242 - acc: 0.2451\n",
      "Test set\n",
      "  Loss: -8.424\n",
      "  Accuracy: 0.245\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tk.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = tf.keras.preprocessing.sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
